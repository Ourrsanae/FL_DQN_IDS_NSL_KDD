{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "from collections import deque\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Seed pour reproductibilit√©\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "print(\" Imports OK\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration du chemin des donn√©es\n",
    "DATA_DIR = r\"/kaggle/input/nslkdd\"\n",
    "\n",
    "# D√©finition des 41 features + label + difficulty\n",
    "column_names = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes',\n",
    "    'land', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'logged_in',\n",
    "    'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
    "    'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
    "    'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate',\n",
    "    'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate',\n",
    "    'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count',\n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate',\n",
    "    'dst_host_rerror_rate', 'dst_host_srv_rerror_rate',\n",
    "    'label', 'difficulty'\n",
    "]\n",
    "\n",
    "# Chargement KDDTrain+\n",
    "try:\n",
    "    train_data = pd.read_csv(f\"{DATA_DIR}/KDDTrain+.txt\", header=None, names=column_names)\n",
    "except:\n",
    "    train_data = pd.read_csv(f\"{DATA_DIR}/KDDTrain+\", header=None, names=column_names)\n",
    "\n",
    "# Chargement KDDTest+\n",
    "try:\n",
    "    test_data = pd.read_csv(f\"{DATA_DIR}/KDDTest+.txt\", header=None, names=column_names)\n",
    "except:\n",
    "    test_data = pd.read_csv(f\"{DATA_DIR}/KDDTest+\", header=None, names=column_names)\n",
    "\n",
    "# Suppression de la colonne difficulty\n",
    "train_data = train_data.drop(columns=['difficulty'])\n",
    "test_data = test_data.drop(columns=['difficulty'])\n",
    "\n",
    "print(f\" Train shape: {train_data.shape}\")\n",
    "print(f\" Test shape: {test_data.shape}\")\n",
    "print(\"\\n Premi√®res lignes:\")\n",
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversion label binaire\n",
    "train_data['binary_label'] = train_data['label'].apply(lambda x: 0 if x == 'normal' else 1)\n",
    "test_data['binary_label'] = test_data['label'].apply(lambda x: 0 if x == 'normal' else 1)\n",
    "\n",
    "# Sauvegarde des labels multi-classe pour le split Non-IID\n",
    "train_data['attack_type'] = train_data['label'].apply(\n",
    "    lambda x: 'normal' if x == 'normal' else (\n",
    "        'DoS' if x in ['back', 'land', 'neptune', 'pod', 'smurf', 'teardrop', 'apache2', 'udpstorm', 'processtable', 'worm'] else (\n",
    "        'Probe' if x in ['ipsweep', 'nmap', 'portsweep', 'satan', 'mscan', 'saint'] else (\n",
    "        'R2L' if x in ['ftp_write', 'guess_passwd', 'imap', 'multihop', 'phf', 'spy', 'warezclient', 'warezmaster', 'sendmail', 'named', 'snmpgetattack', 'snmpguess', 'xlock', 'xsnoop', 'httptunnel'] else 'U2R'\n",
    "        )\n",
    "    ))\n",
    ")\n",
    "\n",
    "print(\"\\n Distribution des classes (Train):\")\n",
    "print(train_data['binary_label'].value_counts())\n",
    "print(f\"Ratio Attack/Normal: {train_data['binary_label'].sum() / len(train_data):.2%}\")\n",
    "\n",
    "print(\"\\n Distribution par type d'attaque:\")\n",
    "print(train_data['attack_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  OneHot Encoding des colonnes cat√©gorielles\n",
    "categorical_cols = ['protocol_type', 'service', 'flag']\n",
    "\n",
    "train_encoded = pd.get_dummies(train_data, columns=categorical_cols)\n",
    "test_encoded = pd.get_dummies(test_data, columns=categorical_cols)\n",
    "\n",
    "# Aligner les colonnes train/test\n",
    "train_encoded, test_encoded = train_encoded.align(test_encoded, join='left', axis=1, fill_value=0)\n",
    "\n",
    "print(f\" Shape apr√®s encodage: {train_encoded.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  S√©paration features / labels\n",
    "cols_to_drop = ['label', 'binary_label', 'attack_type']\n",
    "X_train = train_encoded.drop(columns=cols_to_drop)\n",
    "y_train = train_encoded['binary_label'].values\n",
    "attack_types_train = train_data['attack_type'].values\n",
    "\n",
    "X_test = test_encoded.drop(columns=cols_to_drop)\n",
    "y_test = test_encoded['binary_label'].values\n",
    "\n",
    "# Normalisation MinMax\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\" X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
    "print(f\" X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
    "print(f\" Features normalis√©es dans [0, 1]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 5\n",
    "\n",
    "# Cr√©er les indices pour chaque type\n",
    "normal_idx = np.where(attack_types_train == 'normal')[0]\n",
    "dos_idx = np.where(attack_types_train == 'DoS')[0]\n",
    "probe_idx = np.where(attack_types_train == 'Probe')[0]\n",
    "r2l_idx = np.where(attack_types_train == 'R2L')[0]\n",
    "u2r_idx = np.where(attack_types_train == 'U2R')[0]\n",
    "\n",
    "# Shuffle\n",
    "np.random.shuffle(normal_idx)\n",
    "np.random.shuffle(dos_idx)\n",
    "np.random.shuffle(probe_idx)\n",
    "np.random.shuffle(r2l_idx)\n",
    "np.random.shuffle(u2r_idx)\n",
    "\n",
    "# Split normal data\n",
    "normal_split = np.array_split(normal_idx, NUM_CLIENTS)\n",
    "\n",
    "# Distribution Non-IID\n",
    "client_data = {}\n",
    "\n",
    "# Client 1: Normal + 70% DoS\n",
    "dos_split = int(len(dos_idx) * 0.7)\n",
    "client_data[0] = np.concatenate([normal_split[0], dos_idx[:dos_split]])\n",
    "\n",
    "# Client 2: Normal + 70% Probe\n",
    "probe_split = int(len(probe_idx) * 0.7)\n",
    "client_data[1] = np.concatenate([normal_split[1], probe_idx[:probe_split]])\n",
    "\n",
    "# Client 3: Normal + 70% R2L\n",
    "r2l_split = int(len(r2l_idx) * 0.7)\n",
    "client_data[2] = np.concatenate([normal_split[2], r2l_idx[:r2l_split]])\n",
    "\n",
    "# Client 4: Normal + 70% U2R\n",
    "u2r_split = int(len(u2r_idx) * 0.7)\n",
    "client_data[3] = np.concatenate([normal_split[3], u2r_idx[:u2r_split]])\n",
    "\n",
    "# Client 5: Mix √©quilibr√© (reste)\n",
    "remaining = np.concatenate([\n",
    "    normal_split[4],\n",
    "    dos_idx[dos_split:],\n",
    "    probe_idx[probe_split:],\n",
    "    r2l_idx[r2l_split:],\n",
    "    u2r_idx[u2r_split:]\n",
    "])\n",
    "client_data[4] = remaining\n",
    "\n",
    "# Shuffle chaque client\n",
    "for i in range(NUM_CLIENTS):\n",
    "    np.random.shuffle(client_data[i])\n",
    "\n",
    "# Afficher statistiques\n",
    "print(\"\\n Distribution par client (Non-IID):\")\n",
    "print(\"=\"*60)\n",
    "for i in range(NUM_CLIENTS):\n",
    "    idx = client_data[i]\n",
    "    n_samples = len(idx)\n",
    "    n_attacks = y_train[idx].sum()\n",
    "    ratio = n_attacks / n_samples\n",
    "    print(f\"Client {i+1}: {n_samples:6d} samples | Attacks: {n_attacks:5d} ({ratio:.2%})\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\" Total samples distributed: {sum(len(client_data[i]) for i in range(NUM_CLIENTS))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDSEnvironment:\n",
    "    \"\"\"\n",
    "    Environnement RL pour d√©tection d'intrusion.\n",
    "    Simule un environnement o√π chaque √©tat est une connexion r√©seau.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_samples = len(X)\n",
    "        self.current_idx = 0\n",
    "        self.indices = np.arange(self.n_samples)\n",
    "        np.random.shuffle(self.indices)\n",
    "        \n",
    "    def reset(self):\n",
    "        \"\"\"R√©initialise l'environnement et retourne le premier √©tat.\"\"\"\n",
    "        self.current_idx = 0\n",
    "        np.random.shuffle(self.indices)\n",
    "        return self.X[self.indices[self.current_idx]]\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Ex√©cute une action et retourne (next_state, reward, done, info).\n",
    "        \n",
    "        Args:\n",
    "            action: 0 (normal) ou 1 (attack)\n",
    "        \n",
    "        Returns:\n",
    "            next_state, reward, done, info\n",
    "        \"\"\"\n",
    "        true_label = self.y[self.indices[self.current_idx]]\n",
    "        \n",
    "        # Reward: +1 si correct, -1 si incorrect\n",
    "        reward = 1.0 if action == true_label else -1.0\n",
    "        \n",
    "        # Passer au sample suivant\n",
    "        self.current_idx += 1\n",
    "        done = self.current_idx >= self.n_samples\n",
    "        \n",
    "        if done:\n",
    "            next_state = np.zeros_like(self.X[0])\n",
    "        else:\n",
    "            next_state = self.X[self.indices[self.current_idx]]\n",
    "        \n",
    "        info = {'true_label': true_label}\n",
    "        \n",
    "        return next_state, reward, done, info\n",
    "\n",
    "print(\" IDSEnvironment class d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \"\"\"Deep Q-Network pour d√©tection d'intrusion.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden1=128, hidden2=64, output_dim=2):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden1)\n",
    "        self.fc2 = nn.Linear(hidden1, hidden2)\n",
    "        self.fc3 = nn.Linear(hidden2, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "print(\" DQN class d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    \"\"\"Buffer pour stocker les transitions (s, a, r, s', done).\"\"\"\n",
    "    \n",
    "    def __init__(self, capacity=10000):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "    \n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "    \n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        batch = [self.buffer[i] for i in indices]\n",
    "        \n",
    "        states = np.array([b[0] for b in batch])\n",
    "        actions = np.array([b[1] for b in batch])\n",
    "        rewards = np.array([b[2] for b in batch])\n",
    "        next_states = np.array([b[3] for b in batch])\n",
    "        dones = np.array([b[4] for b in batch])\n",
    "        \n",
    "        return states, actions, rewards, next_states, dones\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "print(\" ReplayBuffer class d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_local_dqn(client_idx, client_indices, global_weights, input_dim, \n",
    "                     episodes=5, epsilon=0.1, gamma=0.99, lr=0.001, \n",
    "                     batch_size=64, buffer_capacity=10000):\n",
    "    \"\"\"\n",
    "    Entra√Æne un agent DQN local pour un client.\n",
    "    \n",
    "    Args:\n",
    "        client_idx: Index du client\n",
    "        client_indices: Indices des donn√©es du client\n",
    "        global_weights: Poids du mod√®le global √† initialiser\n",
    "        input_dim: Dimension des features\n",
    "        episodes: Nombre d'√©pisodes d'entra√Ænement\n",
    "        epsilon: Taux d'exploration\n",
    "        gamma: Facteur de discount\n",
    "        lr: Learning rate\n",
    "        batch_size: Taille du batch\n",
    "        buffer_capacity: Capacit√© du replay buffer\n",
    "    \n",
    "    Returns:\n",
    "        model_weights: Poids du mod√®le apr√®s entra√Ænement\n",
    "        metrics: Dictionnaire de m√©triques (loss, reward, accuracy)\n",
    "    \"\"\"\n",
    "    # Donn√©es du client\n",
    "    X_client = X_train[client_indices]\n",
    "    y_client = y_train[client_indices]\n",
    "    \n",
    "    # Initialisation du mod√®le\n",
    "    policy_net = DQN(input_dim)\n",
    "    target_net = DQN(input_dim)\n",
    "    \n",
    "    if global_weights is not None:\n",
    "        policy_net.load_state_dict(global_weights)\n",
    "        target_net.load_state_dict(global_weights)\n",
    "    else:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "    \n",
    "    optimizer = optim.Adam(policy_net.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    # Replay buffer\n",
    "    replay_buffer = ReplayBuffer(buffer_capacity)\n",
    "    \n",
    "    # Environnement\n",
    "    env = IDSEnvironment(X_client, y_client)\n",
    "    \n",
    "    total_loss = 0\n",
    "    total_reward = 0\n",
    "    total_steps = 0\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        state = env.reset()\n",
    "        episode_reward = 0\n",
    "        done = False\n",
    "        \n",
    "        while not done:\n",
    "            # Œµ-greedy action selection\n",
    "            if np.random.rand() < epsilon:\n",
    "                action = np.random.randint(0, 2)\n",
    "            else:\n",
    "                with torch.no_grad():\n",
    "                    state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "                    q_values = policy_net(state_tensor)\n",
    "                    action = q_values.argmax().item()\n",
    "            \n",
    "            # Step\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            # Stocker dans le buffer\n",
    "            replay_buffer.push(state, action, reward, next_state, done)\n",
    "            \n",
    "            episode_reward += reward\n",
    "            if reward > 0:\n",
    "                correct_predictions += 1\n",
    "            \n",
    "            state = next_state\n",
    "            total_steps += 1\n",
    "            \n",
    "            # Training step\n",
    "            if len(replay_buffer) >= batch_size:\n",
    "                states, actions, rewards, next_states, dones = replay_buffer.sample(batch_size)\n",
    "                \n",
    "                states_t = torch.FloatTensor(states)\n",
    "                actions_t = torch.LongTensor(actions)\n",
    "                rewards_t = torch.FloatTensor(rewards)\n",
    "                next_states_t = torch.FloatTensor(next_states)\n",
    "                dones_t = torch.FloatTensor(dones)\n",
    "                \n",
    "                # Q(s,a)\n",
    "                current_q = policy_net(states_t).gather(1, actions_t.unsqueeze(1)).squeeze(1)\n",
    "                \n",
    "                # max Q(s',a')\n",
    "                with torch.no_grad():\n",
    "                    next_q = target_net(next_states_t).max(1)[0]\n",
    "                    target_q = rewards_t + gamma * next_q * (1 - dones_t)\n",
    "                \n",
    "                # Loss\n",
    "                loss = criterion(current_q, target_q)\n",
    "                \n",
    "                # Optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        total_reward += episode_reward\n",
    "    \n",
    "    # Update target network\n",
    "    target_net.load_state_dict(policy_net.state_dict())\n",
    "    \n",
    "    # Metrics\n",
    "    avg_loss = total_loss / max(total_steps - batch_size, 1)\n",
    "    avg_reward = total_reward / episodes\n",
    "    accuracy = correct_predictions / total_steps if total_steps > 0 else 0\n",
    "    \n",
    "    metrics = {\n",
    "        'loss': avg_loss,\n",
    "        'reward': avg_reward,\n",
    "        'accuracy': accuracy,\n",
    "        'n_samples': len(client_indices)\n",
    "    }\n",
    "    \n",
    "    return policy_net.state_dict(), metrics\n",
    "\n",
    "print(\" train_local_dqn function d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fedavg_aggregate(client_weights, client_metrics):\n",
    "    \"\"\"\n",
    "    Agr√©gation FedAvg: moyenne pond√©r√©e par nombre de samples.\n",
    "    \"\"\"\n",
    "    total_samples = sum(m['n_samples'] for m in client_metrics)\n",
    "    \n",
    "    # Initialiser les poids globaux\n",
    "    global_weights = copy.deepcopy(client_weights[0])\n",
    "    \n",
    "    for key in global_weights.keys():\n",
    "        global_weights[key] = torch.zeros_like(global_weights[key], dtype=torch.float32)\n",
    "        \n",
    "        for i, w in enumerate(client_weights):\n",
    "            weight = client_metrics[i]['n_samples'] / total_samples\n",
    "            global_weights[key] += w[key].float() * weight\n",
    "    \n",
    "    return global_weights\n",
    "\n",
    "print(\" fedavg_aggregate function d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_aggregate(client_weights, client_metrics):\n",
    "    \"\"\"\n",
    "    Agr√©gation avec attention dynamique.\n",
    "    \n",
    "    attention_multiplier_i = 1 + (1 - accuracy_i)\n",
    "    attention_i = n_samples_i * attention_multiplier_i\n",
    "    \"\"\"\n",
    "    attention_weights = []\n",
    "    \n",
    "    for m in client_metrics:\n",
    "        accuracy = m['accuracy']\n",
    "        n_samples = m['n_samples']\n",
    "        \n",
    "        # Attention multiplier: plus l'accuracy est faible, plus le poids est √©lev√©\n",
    "        # Cela permet de donner plus d'importance aux clients qui ont des difficult√©s\n",
    "        attention_multiplier = 1 + (1 - accuracy)\n",
    "        attention = n_samples * attention_multiplier\n",
    "        \n",
    "        attention_weights.append(attention)\n",
    "    \n",
    "    total_attention = sum(attention_weights)\n",
    "    \n",
    "    # Normaliser\n",
    "    attention_weights = [a / total_attention for a in attention_weights]\n",
    "    \n",
    "    # Agr√©gation\n",
    "    global_weights = copy.deepcopy(client_weights[0])\n",
    "    \n",
    "    for key in global_weights.keys():\n",
    "        global_weights[key] = torch.zeros_like(global_weights[key], dtype=torch.float32)\n",
    "        \n",
    "        for i, w in enumerate(client_weights):\n",
    "            global_weights[key] += w[key].float() * attention_weights[i]\n",
    "    \n",
    "    print(\"\\n Coefficients d'attention:\")\n",
    "    for i, (att, m) in enumerate(zip(attention_weights, client_metrics)):\n",
    "        print(f\"  Client {i+1}: {att:.4f} (acc={m['accuracy']:.2%}, samples={m['n_samples']})\")\n",
    "    \n",
    "    return global_weights, attention_weights\n",
    "\n",
    "print(\"attention_aggregate function d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam√®tres\n",
    "ROUNDS = 10\n",
    "EPISODES_PER_ROUND = 3\n",
    "INPUT_DIM = X_train.shape[1]\n",
    "\n",
    "print(f\" Configuration FL-DQN:\")\n",
    "print(f\"  - Rounds: {ROUNDS}\")\n",
    "print(f\"  - Episodes par round: {EPISODES_PER_ROUND}\")\n",
    "print(f\"  - Input dimension: {INPUT_DIM}\")\n",
    "print(f\"  - Nombre de clients: {NUM_CLIENTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== RUN 1: FedAvg ==========\n",
    "print(\" D√âBUT ENTRA√éNEMENT FL-DQN FEDAVG\")\n",
    "\n",
    "global_weights_fedavg = None\n",
    "history_fedavg = {'accuracy': [], 'loss': [], 'reward': []}\n",
    "\n",
    "for round_num in range(ROUNDS):\n",
    "    print(f\"\\n--- Round {round_num + 1}/{ROUNDS} ---\")\n",
    "    \n",
    "    client_weights = []\n",
    "    client_metrics = []\n",
    "    \n",
    "    # Entra√Ænement local de chaque client\n",
    "    for client_idx in range(NUM_CLIENTS):\n",
    "        weights, metrics = train_local_dqn(\n",
    "            client_idx=client_idx,\n",
    "            client_indices=client_data[client_idx],\n",
    "            global_weights=global_weights_fedavg,\n",
    "            input_dim=INPUT_DIM,\n",
    "            episodes=EPISODES_PER_ROUND,\n",
    "            epsilon=0.1,\n",
    "            lr=0.001\n",
    "        )\n",
    "        client_weights.append(weights)\n",
    "        client_metrics.append(metrics)\n",
    "    \n",
    "    # Agr√©gation FedAvg\n",
    "    global_weights_fedavg = fedavg_aggregate(client_weights, client_metrics)\n",
    "    \n",
    "    # M√©triques moyennes\n",
    "    avg_accuracy = np.mean([m['accuracy'] for m in client_metrics])\n",
    "    avg_reward = np.mean([m['reward'] for m in client_metrics])\n",
    "    \n",
    "    history_fedavg['accuracy'].append(avg_accuracy)\n",
    "    history_fedavg['loss'].append(avg_loss)\n",
    "    history_fedavg['reward'].append(avg_reward)\n",
    "    \n",
    "    print(f\"  Avg Accuracy: {avg_accuracy:.4f} | Loss: {avg_loss:.4f} | Reward: {avg_reward:.2f}\")\n",
    "\n",
    "print(\"\\n Entra√Ænement FedAvg termin√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== RUN 2: Attention ==========\n",
    "print(\"üöÄ D√âBUT ENTRA√éNEMENT FL-DQN ATTENTION\")\n",
    "\n",
    "global_weights_attention = None\n",
    "history_attention = {'accuracy': [], 'loss': [], 'reward': [], 'attention_weights': []}\n",
    "\n",
    "for round_num in range(ROUNDS):\n",
    "    print(f\"\\n--- Round {round_num + 1}/{ROUNDS} ---\")\n",
    "    \n",
    "    client_weights = []\n",
    "    client_metrics = []\n",
    "    \n",
    "    # Entra√Ænement local de chaque client\n",
    "    for client_idx in range(NUM_CLIENTS):\n",
    "        weights, metrics = train_local_dqn(\n",
    "            client_idx=client_idx,\n",
    "            client_indices=client_data[client_idx],\n",
    "            global_weights=global_weights_attention,\n",
    "            input_dim=INPUT_DIM,\n",
    "            episodes=EPISODES_PER_ROUND,\n",
    "            epsilon=0.1,\n",
    "            lr=0.001\n",
    "        )\n",
    "        client_weights.append(weights)\n",
    "        client_metrics.append(metrics)\n",
    "    \n",
    "    # Agr√©gation Attention\n",
    "    global_weights_attention, attention_w = attention_aggregate(client_weights, client_metrics)\n",
    "    \n",
    "    # M√©triques moyennes\n",
    "    avg_accuracy = np.mean([m['accuracy'] for m in client_metrics])\n",
    "    avg_loss = np.mean([m['loss'] for m in client_metrics])\n",
    "    avg_reward = np.mean([m['reward'] for m in client_metrics])\n",
    "    \n",
    "    history_attention['accuracy'].append(avg_accuracy)\n",
    "    history_attention['loss'].append(avg_loss)\n",
    "    history_attention['reward'].append(avg_reward)\n",
    "    history_attention['attention_weights'].append(attention_w)\n",
    "    \n",
    "    print(f\"  Avg Accuracy: {avg_accuracy:.4f} | Loss: {avg_loss:.4f} | Reward: {avg_reward:.2f}\")\n",
    "\n",
    "print(\"\\n Entra√Ænement Attention termin√©\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de l'entra√Ænement\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].plot(history_fedavg['accuracy'], label='FedAvg', marker='o')\n",
    "axes[0].plot(history_attention['accuracy'], label='Attention', marker='s')\n",
    "axes[0].set_xlabel('Round')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Training Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Loss\n",
    "axes[1].plot(history_fedavg['loss'], label='FedAvg', marker='o')\n",
    "axes[1].plot(history_attention['loss'], label='Attention', marker='s')\n",
    "axes[1].set_xlabel('Round')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].set_title('Training Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Reward\n",
    "axes[2].plot(history_fedavg['reward'], label='FedAvg', marker='o')\n",
    "axes[2].plot(history_attention['reward'], label='Attention', marker='s')\n",
    "axes[2].set_xlabel('Round')\n",
    "axes[2].set_ylabel('Avg Reward')\n",
    "axes[2].set_title('Training Reward')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_weights, X, y, model_name=\"Model\"):\n",
    "    \"\"\"\n",
    "    √âvalue un mod√®le DQN sur un dataset de test.\n",
    "    \"\"\"\n",
    "    model = DQN(X.shape[1])\n",
    "    model.load_state_dict(model_weights)\n",
    "    model.eval()\n",
    "    \n",
    "    # Pr√©dictions\n",
    "    with torch.no_grad():\n",
    "        X_tensor = torch.FloatTensor(X)\n",
    "        outputs = model(X_tensor)\n",
    "        y_pred = outputs.argmax(dim=1).numpy()\n",
    "        y_pred_proba = torch.softmax(outputs, dim=1)[:, 1].numpy()\n",
    "    \n",
    "    # M√©triques\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    prec = precision_score(y, y_pred, zero_division=0)\n",
    "    rec = recall_score(y, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y, y_pred, zero_division=0)\n",
    "    auc_score = roc_auc_score(y, y_pred_proba)\n",
    "    \n",
    "    # FPR\n",
    "    cm = confusion_matrix(y, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
    "    \n",
    "    results = {\n",
    "        'model': model_name,\n",
    "        'accuracy': acc,\n",
    "        'precision': prec,\n",
    "        'recall': rec,\n",
    "        'f1': f1,\n",
    "        'auc': auc_score,\n",
    "        'fpr': fpr,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'cm': cm\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\" evaluate_model function d√©finie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Baseline centralis√© (MLP sklearn)\n",
    "print(\"\\n Training centralized baseline (MLP)\")\n",
    "mlp_baseline = MLPClassifier(hidden_layer_sizes=(128, 64), max_iter=50, random_state=SEED)\n",
    "mlp_baseline.fit(X_train, y_train)\n",
    "y_pred_mlp = mlp_baseline.predict(X_test)\n",
    "y_pred_proba_mlp = mlp_baseline.predict_proba(X_test)[:, 1]\n",
    "\n",
    "acc_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "prec_mlp = precision_score(y_test, y_pred_mlp, zero_division=0)\n",
    "rec_mlp = recall_score(y_test, y_pred_mlp, zero_division=0)\n",
    "f1_mlp = f1_score(y_test, y_pred_mlp, zero_division=0)\n",
    "auc_mlp = roc_auc_score(y_test, y_pred_proba_mlp)\n",
    "\n",
    "cm_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "tn, fp, fn, tp = cm_mlp.ravel()\n",
    "fpr_mlp = fp / (fp + tn)\n",
    "\n",
    "results_mlp = {\n",
    "    'model': 'Centralized MLP',\n",
    "    'accuracy': acc_mlp,\n",
    "    'precision': prec_mlp,\n",
    "    'recall': rec_mlp,\n",
    "    'f1': f1_mlp,\n",
    "    'auc': auc_mlp,\n",
    "    'fpr': fpr_mlp,\n",
    "    'y_pred': y_pred_mlp,\n",
    "    'y_pred_proba': y_pred_proba_mlp,\n",
    "    'cm': cm_mlp\n",
    "}\n",
    "\n",
    "print(f\"  Accuracy: {acc_mlp:.4f} | F1: {f1_mlp:.4f} | AUC: {auc_mlp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. FL-DQN FedAvg\n",
    "print(\"\\n  Evaluating FL-DQN FedAvg...\")\n",
    "results_fedavg = evaluate_model(global_weights_fedavg, X_test, y_test, \"FL-DQN FedAvg\")\n",
    "print(f\"  Accuracy: {results_fedavg['accuracy']:.4f} | F1: {results_fedavg['f1']:.4f} | AUC: {results_fedavg['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. FL-DQN Attention\n",
    "print(\"\\n Evaluating FL-DQN Attention...\")\n",
    "results_attention = evaluate_model(global_weights_attention, X_test, y_test, \"FL-DQN Attention\")\n",
    "print(f\"  Accuracy: {results_attention['accuracy']:.4f} | F1: {results_attention['f1']:.4f} | AUC: {results_attention['auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation: Matrices de confusion\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for ax, res in zip(axes, [results_mlp, results_fedavg, results_attention]):\n",
    "    sns.heatmap(res['cm'], annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_title(f\"{res['model']}\\nAcc={res['accuracy']:.3f}\")\n",
    "    ax.set_xlabel('Predicted')\n",
    "    ax.set_ylabel('True')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation: Courbes ROC\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for res in [results_mlp, results_fedavg, results_attention]:\n",
    "    fpr_roc, tpr, _ = roc_curve(y_test, res['y_pred_proba'])\n",
    "    plt.plot(fpr_roc, tpr, label=f\"{res['model']} (AUC={res['auc']:.3f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tableau comparatif\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\n",
    "        'M√©thode': results_mlp['model'],\n",
    "        'Accuracy': f\"{results_mlp['accuracy']:.4f}\",\n",
    "        'Precision': f\"{results_mlp['precision']:.4f}\",\n",
    "        'Recall': f\"{results_mlp['recall']:.4f}\",\n",
    "        'F1-Score': f\"{results_mlp['f1']:.4f}\",\n",
    "        'ROC-AUC': f\"{results_mlp['auc']:.4f}\",\n",
    "        'FPR': f\"{results_mlp['fpr']:.4f}\"\n",
    "    },\n",
    "    {\n",
    "        'M√©thode': results_fedavg['model'],\n",
    "        'Accuracy': f\"{results_fedavg['accuracy']:.4f}\",\n",
    "        'Precision': f\"{results_fedavg['precision']:.4f}\",\n",
    "        'Recall': f\"{results_fedavg['recall']:.4f}\",\n",
    "        'F1-Score': f\"{results_fedavg['f1']:.4f}\",\n",
    "        'ROC-AUC': f\"{results_fedavg['auc']:.4f}\",\n",
    "        'FPR': f\"{results_fedavg['fpr']:.4f}\"\n",
    "    },\n",
    "    {\n",
    "        'M√©thode': results_attention['model'],\n",
    "        'Accuracy': f\"{results_attention['accuracy']:.4f}\",\n",
    "        'Precision': f\"{results_attention['precision']:.4f}\",\n",
    "        'Recall': f\"{results_attention['recall']:.4f}\",\n",
    "        'F1-Score': f\"{results_attention['f1']:.4f}\",\n",
    "        'ROC-AUC': f\"{results_attention['auc']:.4f}\",\n",
    "        'FPR': f\"{results_attention['fpr']:.4f}\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" TABLEAU COMPARATIF DES PERFORMANCES\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Analyse des r√©sultats\n",
    "\n",
    "**Pourquoi l'attention dynamique aide en contexte Non-IID ?**\n",
    "\n",
    "1. **Gestion de l'h√©t√©rog√©n√©it√©** : L'attention dynamique pond√®re les contributions des clients en fonction de leur performance locale.\n",
    "   \n",
    "2. **Compensation des biais** : Les clients avec des donn√©es plus difficiles ou d√©s√©quilibr√©es (faible accuracy) re√ßoivent un poids plus √©lev√©, permettant au mod√®le global de mieux g√©n√©raliser.\n",
    "\n",
    "3. **Adaptation aux distributions locales** : Contrairement √† FedAvg qui pond√®re uniquement par le nombre d'√©chantillons, l'attention consid√®re aussi la \"difficult√©\" des donn√©es, ce qui est crucial en Non-IID.\n",
    "\n",
    "4. **Convergence robuste** : L'agr√©gation par attention permet une convergence plus stable face aux variations de distributions entre clients.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limites et perspectives\n",
    "\n",
    "###  Limites de cette impl√©mentation\n",
    "\n",
    "1. **Simulation RL** : Le RL est simul√© sur un dataset tabulaire statique. Un vrai environnement RL n√©cessiterait des interactions temps r√©el avec le r√©seau.\n",
    "\n",
    "2. **Communication** : Nous n'avons pas mod√©lis√© les co√ªts de communication ni les d√©lais r√©seau entre clients et serveur.\n",
    "\n",
    "3. **Attaques FL** : Aucune protection contre les attaques de type poisoning, backdoor ou model inversion.\n",
    "\n",
    "4. **Classification binaire uniquement** : Pas de d√©tection multi-classe des types d'attaques (DoS, Probe, R2L, U2R).\n",
    "\n",
    "5. **Scalabilit√©** : L'impl√©mentation est limit√©e √† 5 clients ; un vrai d√©ploiement n√©cessiterait des centaines de clients.\n",
    "\n",
    "---\n",
    "\n",
    "###  Perspectives d'am√©lioration\n",
    "\n",
    "1. **Multi-classe** : √âtendre √† la classification multi-classe pour identifier le type d'attaque.\n",
    "\n",
    "2. **Vrai r√©seau distribu√©** : D√©ployer sur plusieurs machines avec communication r√©elle (ex: gRPC, WebSockets).\n",
    "\n",
    "3. **Robust Aggregation** : Impl√©menter des m√©canismes de d√©fense (ex: Krum, Trimmed Mean, Byzantine-robust FL).\n",
    "\n",
    "4. **Prioritized Experience Replay** : Am√©liorer le DQN avec PER pour un apprentissage plus efficace.\n",
    "\n",
    "5. **Privacy-preserving FL** : Ajouter du differential privacy et du secure aggregation.\n",
    "\n",
    "6. **Datasets r√©els** : Tester sur des datasets plus r√©cents (CICIDS2017, CSE-CIC-IDS2018, UNSW-NB15).\n",
    "\n",
    "7. **Hyperparameter tuning** : Optimiser epsilon, learning rate, buffer size, etc.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
